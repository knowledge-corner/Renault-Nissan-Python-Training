{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d8697df-0698-4232-96af-5fd6122dae98",
   "metadata": {},
   "source": [
    "#### Coffee Sales Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b074b23a-191d-4f0c-847b-394fe11f8502",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (3, 2)\n",
    "\n",
    "df = pd.read_csv(\"coffee_sales.csv\", header=3)\n",
    "df.dropna(axis=1, how=\"all\", inplace=True)\n",
    "df.dropna(axis=0, how=\"all\", inplace=True)\n",
    "\n",
    "obj = str.maketrans(\"\", \"\", \"$,\")\n",
    "df[\"Sales\"] = df[\"Sales\"].str.translate(obj).astype(float)\n",
    "df[\"Target Sales\"] = df[\"Target Sales\"].str.translate(obj).astype(float)\n",
    "df[\"Profit\"] = df[\"Profit\"].str.translate(obj).astype(float)\n",
    "df[\"Target Profit\"] = df[\"Target Profit\"].str.translate(obj).astype(float)\n",
    "\n",
    "df[\"Target Status\"] = np.where(df.Sales >= df[\"Target Sales\"], \"Achieved\", \"Not Achieved\")\n",
    "status = np.where(df.Profit >= df[\"Target Profit\"], \"Achieved\", \"Not Achieved\")\n",
    "df.insert(7, \"Target Profit Status\", status)\n",
    "\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"], format=\"mixed\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749c3adc-42d7-4da2-9050-ff994041fe60",
   "metadata": {},
   "source": [
    "### Operations on DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095bbccd-d081-4526-ba02-7b9c1171042d",
   "metadata": {},
   "source": [
    "- Adding new column by calculation\n",
    "- Sorting and Ranking\n",
    "- map(), replace(), apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebd3443-d814-4b5d-8340-7964836178ad",
   "metadata": {},
   "source": [
    "###### Ex. Add column Target Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d5b795-f3c2-4bb4-967a-84d15760487c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Target Status\"] = np.where(df.Sales >= df[\"Target Sales\"], \"Achieved\", \"Not Achieved\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550b58bd-273f-4792-9246-f1c6a1592533",
   "metadata": {},
   "source": [
    "###### Ex. Insert column at specific position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe0e9eb-fe1e-48d7-a943-d96331f7442e",
   "metadata": {},
   "outputs": [],
   "source": [
    "status = np.where(df.Profit >= df[\"Target Profit\"], \"Achieved\", \"Not Achieved\")\n",
    "df.insert(7, \"Target Profit Status\", status)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0d5992-7529-46a7-9a71-348bc7b8984a",
   "metadata": {},
   "source": [
    "###### Ex. Count the number of times the target was achieved versus the number of times it was not achieved.\n",
    "- df.value_counts()\n",
    "- df.plot(kind = \"bar\")\n",
    "- sns.countplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ed44fe-954b-46f0-9c3e-fe7f60854b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd70c40c-10af-4ad2-8d80-5a8e7d43d4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Target Status\"].value_counts() # Series object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620ed28a-a3f6-4dbe-b855-d3807a62b594",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df[\"Target Status\"].value_counts(normalize=True) * 100).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72219431-7f10-45d4-953f-11fc15a48847",
   "metadata": {},
   "source": [
    "###### Ex. Plot the target status on a bar chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfb5bb9-24da-4703-82a7-47cff1da5f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Target Status\"].value_counts().plot(kind = \"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3d3b20-bb49-4b3b-8af7-2d6943c31119",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df[\"Target Status\"].value_counts(normalize=True) * 100).round(2).plot(kind = \"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58ca9d7-3a08-4280-b18e-b0f89f27a733",
   "metadata": {},
   "source": [
    "###### Ex. Plot the profit target status using sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b3bdfb-20f6-469d-9784-8d794589cc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6624b77-8e13-4cd9-97a7-45897eb85067",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sns.countplot(df, x = \"Target Profit Status\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bca893-d4c4-49cf-bf41-59b8626bf26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = dict(zip(df[\"Target Profit Status\"].unique(), [\"lightcoral\",\"limegreen\"]))\n",
    "colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccf3455-bee3-4326-bf58-4a67dead7373",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sns.countplot(data = df, x = \"City\", hue = \"Target Profit Status\", \n",
    "                 palette=colors) # palette takes dict object {status : color}\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99cef9e-ff38-433d-bf90-205cd2a5ca6b",
   "metadata": {},
   "source": [
    "###### Ex. Using bar chart display total sales across products\n",
    "- df.groupby()\n",
    "- sns.barplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65974a0-4b46-4813-830b-6c437bf08912",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"Product\")[\"Sales\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6401a09-2b93-4956-9498-aeef909f9534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using pandas - groupby is mandatory\n",
    "_ = df.groupby(\"Product\")[\"Sales\"].sum().plot(kind = \"bar\", figsize = (10, 2), color = \"teal\")\n",
    "_ = plt.xticks(rotation = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf21e985-4b05-434c-9adb-fe6095a51e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using seaborn\n",
    "plt.figure(figsize=(10, 2))\n",
    "sns.barplot(data=df, x = \"Product\", y=\"Sales\", color = \"teal\", estimator=np.sum, errorbar=None)\n",
    "_ = plt.xticks(rotation = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83df9b84-2c6a-44d6-88c3-11b5b2f8c62e",
   "metadata": {},
   "source": [
    "###### Ex. Display Product wise total Sales and Average Profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fc2846-1b07-42e2-afa1-8f8d0cc89824",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"Product\")[[\"Sales\", \"Profit\"]].sum() # Sales and Profit both agg to sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c31f3f-bc3e-47dc-9e69-b52e8f7264b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"Product\").agg({\"Sales\" : \"sum\", \"Profit\" : \"mean\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bae64db-e2a5-44bc-ad6c-c7e67d3b6e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"Product\").agg({\"Sales\" : \"sum\", \"Profit\" : \"mean\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ece884a-b90b-47e2-9d06-ad5681a6b17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Secondary axis\n",
    "data = df.groupby(\"Product\").agg({\"Sales\" : \"sum\", \"Profit\" : \"mean\"})\n",
    "_ = data.plot(kind = \"bar\", secondary_y = \"Profit\", figsize = (7, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e5ae5c-334c-4e2b-9eb7-f4a137175cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Sub-plots\n",
    "data = df.groupby(\"Product\").agg({\"Sales\" : \"sum\", \"Profit\" : \"mean\"})\n",
    "_ = data.plot(kind = \"bar\", subplots = True, figsize = (7, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c20665c-9bd1-4a6e-ba4b-b132326893e2",
   "metadata": {},
   "source": [
    "#### Working of Datetime format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e62e714-7e98-45d6-b7df-d920e9de1cb1",
   "metadata": {},
   "source": [
    "###### Ex. Convert Date column to datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9c3177-33ee-42f2-862b-35eb585f1dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"], format=\"mixed\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e16dec-7658-438b-bbb8-10af6ddb434e",
   "metadata": {},
   "source": [
    "###### Ex. Extract data for Year 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701d8b99-0beb-4f98-a1da-4e24dcec158c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"Date\"].between(\"2021-01\", \"2021-12\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d648403-6945-4550-82f3-9b908b3ec4c2",
   "metadata": {},
   "source": [
    "###### Ex. Extract data between Jan-2021 to Mar-2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20f1060-0213-432f-b472-9e274ce42fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"Date\"].between(\"2021-01\", \"2021-03\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd5b516-adfd-4290-9c89-4f1a4afb91a3",
   "metadata": {},
   "source": [
    "###### Ex. Extract data for Jan-2021, Mar-2021, Jan-2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bb9fee-f1f3-4560-88b1-11ee2ad5712c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"Date\"].isin((\"2021-01\", \"2021-03\", \"2022-01\"))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4eed538-31ea-401e-84a3-0e89aa256faf",
   "metadata": {},
   "source": [
    "###### Extract Year and Month from date field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87646c8e-0c0e-49f3-876a-224dcfad513e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.insert(1, \"Year\", df.Date.dt.year)\n",
    "df.insert(2, \"Month\", df.Date.dt.month_name())\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e741694c-5c9f-455a-aed3-08994861464f",
   "metadata": {},
   "source": [
    "###### Ex. Extract Data for year 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9bbbf7-6e2a-407a-8a2b-473bebeef9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.Year == 2021]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e2a961-b415-488a-bfb1-a19f6455be7b",
   "metadata": {},
   "source": [
    "###### Ex. Extract Data for Jan-2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a94c89b-7c5b-4557-a709-60ce24b5266a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[np.logical_and(df.Year == 2021, df.Month == \"January\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad99f77c-b658-461c-9bce-82d608295907",
   "metadata": {},
   "source": [
    "###### Ex. Display Trend over the period of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bca2f8-5afd-4ddc-ba64-d0cc8ee641a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "192d8f13-2db4-437d-920e-ff91f9ea5aa9",
   "metadata": {},
   "source": [
    "###### Ex. Display Sales over years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92edb578-9db8-4054-82e7-8ac09d1363ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ff048015-1966-4795-8039-2e8173af5c7a",
   "metadata": {},
   "source": [
    "###### Ex. Display number of franchises where each product sold across cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf35554-e2e1-4773-8b8c-4608296b2c46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebeb8f5-76bf-44a3-8c93-e9e6fe8bd75d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09419ac-de36-4ace-81f8-aea7b7b34b11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ec73cd-26e8-4bf9-94b2-497d0629d678",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f3f5e8-62a5-4ad8-bd31-4d83c3fd1f22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cff002b9-cd87-4d38-9054-939b96034435",
   "metadata": {},
   "source": [
    "<hr><hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097c8308-f824-4fc2-85ca-d5ad9c1a0b7e",
   "metadata": {},
   "source": [
    "## Explolatory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3810a269-29d5-4384-a951-f79037d0d71a",
   "metadata": {},
   "source": [
    "### Types of data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57b45af-89e5-4caf-836f-ed80d2b05d6f",
   "metadata": {},
   "source": [
    "#### Numerical (Quantitative) Data:\n",
    "\n",
    "Numerical data consists of numbers and is measured on a continuous or discrete scale.\n",
    "- Continuous numerical data can take any value within a range (e.g., height, temperature).\n",
    "- Discrete numerical data can take only specific, distinct values (e.g., number of siblings, number of cars).\n",
    "\n",
    "#### Categorical (Qualitative) Data:\n",
    "\n",
    "Categorical data represents categories or labels and is not inherently numerical.\n",
    "- Nominal categorical data has categories with no inherent order or ranking (e.g., gender, eye color).\n",
    "- Ordinal categorical data has categories with a specific order or ranking (e.g., education level, socioeconomic status)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191a8f25-752e-46b2-8c34-03414eb9ed2f",
   "metadata": {},
   "source": [
    "### Population and Sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ed310e-0032-4b22-a019-dcf07f362662",
   "metadata": {},
   "source": [
    "#### Population:\n",
    "\n",
    "The population is the entire group or set of individuals, items, or elements that you are interested in studying and drawing conclusions about. It represents the complete set of possible observations that share a common characteristic or attribute.\n",
    "For example, if you are studying the heights of all adult males in a country, the population would consist of the heights of all adult males in that country.\n",
    "\n",
    "#### Sample:\n",
    "\n",
    "A sample is a subset or a smaller representative group selected from the population.\n",
    "It is used to make inferences or draw conclusions about the population without having to collect data from every individual in the population.\n",
    "\n",
    "The process of selecting a sample from the population is known as sampling.\n",
    "For example, instead of measuring the heights of all adult males in a country (which may be impractical or too costly), you might select a random sample of adult males and measure their heights to estimate the average height of the entire population.\n",
    "\n",
    "#### Key points to note about population and sample:\n",
    "\n",
    "- The population represents the entire group under study, while the sample represents a subset of that group.\n",
    "- In many cases, it is not feasible or practical to collect data from the entire population, so researchers use samples to make inferences about the population.\n",
    "- The goal of sampling is to obtain a representative sample that accurately reflects the characteristics of the population.\n",
    "Statistical techniques are used to analyze sample data and make generalizations or predictions about th##e population.\n",
    "\n",
    "#### Characteristics of Population\n",
    "\n",
    "- Mean (Average): The mean of a population is the average value of a quantitative variable across all individuals in the population. It represents the central tendency of the population distribution.\n",
    "\n",
    "- Median: The median of a population is the middle value of a quantitative variable when all observations are arranged in ascending order. It is another measure of central tendency that is less affected by extreme values (outliers) compared to the mean.\n",
    "\n",
    "- Mode: The mode of a population is the most frequently occurring value or category of a variable. It represents the value with the highest frequency in the population distribution.\n",
    "\n",
    "- Variance: The variance of a population measures the spread or dispersion of values around the mean. It quantifies the average squared deviation of individual observations from the mean.\n",
    "\n",
    "- Standard Deviation: The standard deviation of a population is the square root of the variance. It provides a measure of the average distance between individual observations and the mean.\n",
    "\n",
    "- Range: The range of a population is the difference between the maximum and minimum values of a variable. It provides a simple measure of the spread of values in the population.\n",
    "\n",
    "- Distribution: The distribution of a population describes how the values of a variable are spread or distributed across the population. Common types of distributions include normal (bell-shaped), skewed (asymmetric), and ##uniform (evenly distributed).\n",
    "\n",
    "#### Characteristics of a Sample\n",
    "\n",
    "- Sample Size: The sample size is the number of observations or individuals included in the sample. It represents the amount of data available for analysis and inference.\n",
    "- Sampling Method: The sampling method describes how the sample was selected from the population. Common sampling methods include simple random sampling, stratified sampling, cluster sampling, and systematic sampling.\n",
    "\n",
    "- Descriptive Statistics: Descriptive statistics summarize the main features of the sample data. Common descriptive statistics include measures of central tendency (mean, median, mode), measures of dispersion (range, variance, standard deviation), and measures of shape (skewness, kurtosis).\n",
    "\n",
    "- Sample Proportion: The sample proportion represents the fraction or percentage of observations with a specific attribute or characteristic in the sample. It provides insights into the relative frequency of different categories in the sample.\n",
    "\n",
    "- Confidence Interval: The confidence interval is a range of values that is likely to contain the true population parameter with a certain level of confidence. It is used to estimate the precision or uncertainty of sample statistics, such as the sample mean or proportion.\n",
    "\n",
    "- Sampling Bias: Sampling bias refers to the systematic distortion or deviation of the sample from the population due to the sampling method used. It can affect the representativeness and generalizability of the sample data to the population. the sample data to the population. distributed)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983149c3-e8ac-453a-8aaf-344cc2227e2f",
   "metadata": {},
   "source": [
    "## Types of Variables "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc398a7-64b8-41e2-aa4a-6c3f2cb64540",
   "metadata": {},
   "source": [
    "- **`Features`**: Features, also known as independent variables or input variables, are the attributes or characteristics of the data that are used as input to the machine learning model to make predictions. Features represent the variables that the model learns from to make predictions or classifications. Each feature can be either numerical or categorical and may have different scales or levels of measurement.\n",
    "\n",
    "- **`Labels`**: Labels, also known as target variables or dependent variables, are the outputs or predictions that the machine learning model aims to predict based on the input features. Labels represent the target variable that the model is trying to learn or predict. In supervised learning tasks, the labels are typically known for a subset of the data, and the goal is to train the model to accurately predict the labels for unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674b88cf-4a55-49b4-9a9f-118444cca57c",
   "metadata": {},
   "source": [
    "## Descriptive Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052e5149-cb96-4e76-b8e7-86362d08a6b9",
   "metadata": {},
   "source": [
    "Descriptive statistics deals with summarizing and describing the features of a dataset or sample. Descriptive statistics provides a summary of the main features of the data, including measures of central tendency, dispersion, shape, and relationships between variables.\n",
    "\n",
    "#### Measures of Central Tendency:\n",
    "    - Mean: The average value of the data points.\n",
    "    - Median: The middle value of the data when arranged in ascending order.\n",
    "    - Mode: The most frequently occurring value in the dataset.\n",
    "\n",
    "#### Measures of Dispersion:\n",
    "    - Range: The difference between the maximum and minimum values in the dataset.\n",
    "    - Variance: The average of the squared differences from the mean.\n",
    "    - Standard Deviation: The square root of the variance, representing the average deviation from the mean.\n",
    "\n",
    "#### Measures of Shape:\n",
    "    - Skewness: A measure of the asymmetry of the distribution.\n",
    "        - Positive skewness indicates a longer right tail and a concentration of data on the left side.\n",
    "        - Negative skewness indicates a longer left tail and a concentration of data on the right side.\n",
    "        - Skewness close to zero indicates approximate symmetry around the mean.\n",
    "\n",
    "    - Kurtosis: A measure of the \"peakedness\" or \"flatness\" of the distribution.\n",
    "        - Positive kurtosis indicates heavy tails and a sharp peak (leptokurtic).\n",
    "        - Negative kurtosis indicates light tails and a flat peak (platykurtic).\n",
    "        - A kurtosis of 0 indicates a distribution with similar tails to the normal distribution (mesokurtic).\n",
    "\n",
    "#### Frequency Distribution:\n",
    "    - Frequency table: A table that shows the frequency or count of each value in the dataset.\n",
    "    - Histogram: A graphical representation of the frequency distribution, showing the distribution of values in bins or intervals.\n",
    "\n",
    "#### Measures of Association:\n",
    "    - Correlation: A measure of the strength and direction of the linear relationship between two variables.\n",
    "    - Covariance: A measure of the joint variability between two variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c9e077-812e-47be-aa7b-fab23dd9153a",
   "metadata": {},
   "source": [
    "###### Ex. Find Mean, Median, Mode, Range, Standard Deviation, Skewness, Kurtosis, Frequency Distribution - Histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7375bc9-7db7-4bea-a66a-a45c2e75b547",
   "metadata": {},
   "source": [
    "Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3c35c3-59df-4b94-94d6-25224adc0a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset consists of weights children in the age group of 0 to 10 years\n",
    "weights = np.array([20.8,15.3,23.2,15.5,17.5,27.3,23.3,20.5,16.4,17.4,22.6,20.8,16.7,29.1,14.2,18.5,17.6,17.1,18.2,26.0,25.6,19.1,17.8,21.6,19.6,28.4,19.4,22.8,25.9,27.1,20.8,21.9,15.4,30.2,23.0,25.0,24.0,17.1,18.8,25.8,23.2,14.9,20.4,15.0,12.3,17.6,10.3,12.1,25.8,21.9,9.9,24.8,17.9,22.0,27.6,21.7,26.3,19.9,16.6,17.8,8.0,21.5,17.9,33.6,20.4,21.9,19.8,15.3,25.6,24.7,10.6,22.1,18.8,9.8,14.9,18.7,27.6,21.2,25.1,21.9,22.1,19.6,10.4,17.2,18.3,21.2,21.1,21.0,19.1,14.8,19.2,18.3,22.1,14.1,19.3,16.2,25.6,14.8,22.3,25.0,20.8,21.2,16.6,15.0,15.6,24.7,26.1,18.1,14.1,25.5,21.4,32.7,13.8,27.4,15.8,18.4,21.3,27.5,15.8,27.2,26.9,16.2,22.6,15.3,22.5,26.6,24.7,28.4,28.0,19.9,9.9,16.5,19.5,11.7,27.9,28.1,21.1,20.0,14.5,25.9,13.3,15.8,21.3,10.7,14.6,19.9,21.6,26.6,26.0,23.7,20.5,11.8,15.6,14.9,24.6,20.9,24.5,26.8,25.3,30.9,26.1,14.9,17.9,18.5,25.7,16.4,8.2,24.1,19.5,13.1,17.6,13.4,24.4,16.4,19.9,12.9,14.3,25.4,15.4,17.7,17.3,18.7,16.1,7.4,18.4,16.2,18.7,19.8,25.6,23.7,22.5,20.5,14.9,25.0,4.7,6.8,21.8,22.2,24.4,13.4,32.1,26.6,27.2,17.8,19.6,16.8,14.4,24.9,12.6,15.0,15.4,10.1,12.9,15.9,22.3,15.0,24.4,21.0,17.2,25.2,15.6,24.6,24.9,13.6,10.3,25.6,18.3,25.1,18.1,20.2,29.1,25.7,14.9,11.4,19.2,21.5,13.9,19.5,19.1,23.0,26.8,14.8,24.4,14.7,24.3,24.5,19.9,12.1,21.2,16.4,19.5,25.8,8.5,19.8,23.4,21.3,14.7,17.9,15.7,14.9,5.2,3.8,31.5,17.4,16.0,20.7,18.4,8.1,22.9,32.8,19.0,33.0,26.0,14.2,18.4,15.1,29.5,13.9,5.1,28.1,18.2,10.5,27.8,19.4,13.1,21.9,18.6,11.0,19.7,20.2,20.1,17.6,21.6,21.2,30.0,26.1,20.5,22.8,20.5,19.6,18.0,19.8,21.8,7.0,21.4,22.5,18.9,15.1,22.0,25.5,11.1,15.4,21.5,13.5,11.2,19.3,25.5,20.2,18.3,15.3,40.3,22.1,23.2,17.1,19.4,15.3,28.6,23.0,19.4,16.7,20.9,21.1,15.9,29.6,17.0,19.0,20.8,20.4,9.8,24.0,15.2,26.2,22.0,21.4,16.2,29.2,21.4,28.9,16.9,21.9,11.2,19.0,21.2,20.8,9.3,12.5,26.9,10.7,18.9,17.5,23.3,12.5,13.4,26.3,23.0,21.8,25.6,20.7,18.0,32.5,25.6,8.4,19.8,24.5,18.0,24.7,21.3,12.9,21.6,29.1,25.8,26.4,27.0,25.6,19.0,20.0,10.4,17.5,19.5,17.5,21.1,19.6,23.1,18.2,27.0,18.5,19.3,25.4,20.8,20.8,20.6,20.4,23.1,17.6,18.7,16.2,18.9,15.2,22.5,10.0,21.1,29.3,17.8,27.1,16.8,18.0,28.3,16.5,19.8,16.7,23.2,23.6,18.5,29.8,24.2,22.4,29.3,29.3,21.5,15.5,23.0,12.8,20.8,11.5,20.0,15.2,18.7,17.2,22.5,13.5,13.1,17.6,12.1,23.2,18.0,24.2,7.3,17.0,17.0,22.7,22.1,18.0,15.6,13.9,17.7,14.7,26.1,12.2,20.3,17.8,16.5,10.2,18.2,22.2,26.3,26.6,19.2,19.5,14.3,15.6,13.9,20.2,11.6,31.2,6.3,23.4,21.1,22.0,8.5,11.5,19.3,17.7,11.9,14.8,16.9,16.1,13.0,17.9,22.0,14.2,13.9,25.4,21.1,16.3,16.4,19.3,18.3,23.0,27.4,24.2,14.9,12.7,16.7,17.8,19.5,14.9,23.9,15.2,25.4,22.9,25.2,12.7,26.0,26.7,15.8,24.9,24.4,15.5,20.0,7.8,20.6,19.0,29.8,14.1,14.1,17.8,24.9,20.7,19.8,24.2,16.7,21.3,23.7,20.9,23.6,25.3,9.9,21.7,16.7,10.3,18.9,25.2,12.7,27.4,21.4,23.0,11.8,22.1,13.0,20.0,27.2,19.8,16.9,18.8,25.0,9.0,19.0,11.1,19.6,24.0,29.3,20.7,10.7,26.9,18.6,21.5,26.2,21.5,27.9,22.1,25.1,27.9,18.9,26.4,20.0,25.6,27.5,17.7,18.9,27.0,14.9,27.6,19.6,18.1,19.2,20.2,16.4,16.6,14.1,8.9,17.6,17.3,21.0,14.3,18.7,19.9,12.3,24.4,23.3,25.1,27.9,15.1,18.3,23.2,17.8,15.5,22.0,23.0,20.4,15.5,22.8,19.5,22.2,22.3,25.1,15.0,19.9,23.8,18.8,17.0,7.9,24.0,31.4,17.6,27.4,28.1,17.9,18.3,17.3,21.6,17.8,22.4,19.2,22.8,21.4,19.1,22.4,29.4,13.6,15.0,28.8,18.2,25.8,15.1,23.6,12.2,10.1,15.4,27.0,17.2,11.6,20.8,18.8,20.4,18.1,20.9,31.1,19.0,18.5,17.9,23.1,32.0,21.7,23.4,17.1,19.0,18.1,19.3,18.8,25.8,19.8,22.1,15.8,15.9,21.3,18.4,17.8,23.1,22.2,15.3,20.0,20.8,30.2,24.0,12.6,9.2,21.7,19.8,16.6,16.5,18.0,21.1,10.0,23.5,26.9,23.7,16.8,12.7,29.8,17.9,18.6,19.9,23.6,26.4,18.2,18.1,19.2,15.3,19.4,20.2,33.2,26.2,26.9,15.3,18.9,18.3,27.6,29.0,22.5,30.2,22.8,13.8,21.4,27.3,25.1,26.7,7.9,27.3,21.9,15.6,18.1,19.9,23.0,22.9,15.0,16.5,18.9,24.8,4.9,16.7,20.2,7.9,19.3,16.1,22.5,27.4,29.6,18.7,21.9,9.9,24.6,10.1,21.5,20.6,11.4,14.0,18.4,6.5,12.8,25.5,19.5,14.6,20.5,18.9,14.8,21.7,17.3,33.1,23.1,25.1,30.2,17.0,13.2,29.2,14.8,13.5,22.3,9.0,19.2,19.1,20.4,14.2,20.6,19.3,27.6,21.4,15.5,23.4,13.2,12.1,23.2,33.8,17.5,19.1,23.2,12.6,24.6,14.6,19.5,20.1,13.4,12.4,14.6,16.8,27.5,19.5,11.5,15.4,24.0,21.1,21.8,29.1,18.9,21.3,18.9,20.1,13.7,19.7,17.0,34.0,24.0,16.9,19.3,19.9,19.4,19.3,21.5,20.8,20.1,27.1,23.5,22.9,19.4,14.8,28.6,23.2,8.7,30.1,19.1,15.1,22.3,17.4,23.8,18.1,20.4,23.1,22.4,13.7,25.5,25.9,21.3,21.6,21.4,29.7,18.1,10.3,23.6,21.0,13.1,10.6,20.8,21.7,19.4,21.4,25.1,16.6,11.1,13.8,21.1,22.0,20.8,19.1,24.4,15.2,25.1,19.2,10.5,21.8,17.5,19.6,8.2,22.1,21.8,13.6,15.1,28.4,22.0,28.6,25.3,29.3,19.1,20.8,10.8,23.6,13.5,23.2,16.9,22.9,21.3,21.8,31.3,21.1,17.1,25.5,26.1,19.2,19.9,26.4,34.9,17.4,24.2,17.5,21.7,11.3,4.9,21.3,17.2,15.6,22.4,28.2,22.3,21.3,20.5,18.4,17.5,9.7,21.4,12.8,20.0,20.7,16.1,26.2,20.9,19.2,23.6,22.4,31.7,22.5,20.3,13.8,23.3,17.4,3.0,16.6,17.1,27.8,17.4,13.7,14.1,26.4,23.9,21.2,27.4,9.9,18.7,17.0,21.1,22.9,8.7,19.1,25.1,21.0,22.3,21.5,19.6,17.6,22.7,14.7,11.5,28.6,19.9,13.5,27.3,19.6,18.7,14.0,11.6,15.0,26.5,21.7,22.1,5.7,18.3,23.4,19.5,15.8,18.6,19.3,27.0,21.7,21.9,20.7,13.5,29.7,22.3,24.0,31.1,23.9,15.7,19.6])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fedb4bb-8358-494f-9bf3-283ba2dbdbbe",
   "metadata": {},
   "source": [
    "Example 2 -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9ccc1e-6ca5-4f07-bc2d-617f43ff0fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset consists of Salaries of employees in an organisation\n",
    "salaries = np.array([29756,20014,20347,57214,41327,40209,93390,122004,17725,47210,44386,48407,16837,83731,9130,66723,72525,57347,10941,18726,8913,59251,13090,37983,134656,45499,59533,82998,31440,11672,16295,30676,21822,35263,27340,65522,23380,11662,7066,22403,41230,46693,22478,82491,7347,16263,72672,20522,38409,30175,31383,98820,13605,45096,12397,90988,6602,29786,102559,31790,29768,50085,22649,24426,4059,95210,68657,17799,37370,46160,35133,40969,57201,54757,17973,13610,46004,91341,24474,48005,9473,10277,71287,9383,36492,104352,13473,51293,51911,10026,39992,125885,44462,76531,41512,47267,33231,14180,44474,55702,39554,8359,51892,98574,43638,90568,40508,34129,98497,74784,63383,47197,83519,26458,38642,9629,18404,47324,15793,120345,61126,64613,57964,47582,77944,27082,51891,98126,69008,23284,49785,72406,56418,36769,58715,42999,47333,45733,141091,3848,57584,48356,95301,95269,49894,101380,44028,54577,71055,32066,26596,66653,3179,44484,62889,62952,50903,74656,50733,38180,59410,105003,73854,33579,150293,26348,6769,26315,53038,35766,50517,64714,27523,26867,46607,9882,60052,46653,42143,37371,14475,103629,55402,6149,65128,32861,27603,75553,35641,21457,106916,50369,37731,6473,73858,7716,21144,34340,27917,18150,49270,16344,84532,28616,18452,84678,17990,26463,13671,70005,26237,7245,16941,64383,3317,7275,26981,12600,36983,40054,7283,82140,65120,8259,44235,30682,68578,80737,14009,88942,48374,43148,11447,32203,67168,50149,8607,9680,35442,47306,67316,52503,89884,18337,11798,40659,90852,25479,4737,107231,40006,34020,61695,12128,14126,71024,42150,54591,93625,23809,9698,50910,75967,36494,53497,28006,16650,50352,42133,10915,50698,19962,30772,23430,75790,72083,162101,75728,60565,40074,58299,18280,128972,76801,38314,12744,25607,22188,31862,15955,31175,11044,44390,49677,33251,85617,81684,48054,63108,33461,39505,51449,47547,49199,152777,49820,23147,35010,44921,39633,16546,35436,32229,28603,31804,21668,102866,58514,140647,22149,26732,88552,77813,75665,38038,123394,9457,28241,52657,9075,148287,70362,27398,18672,19003,17600,114609,4318,19729,23148,32015,87090,5342,56550,38458,5400,50686,46353,14777,19302,16606,21645,37117,22488,5465,28650,57321,34736,43956,37151,9776,37461,17631,98557,18773,15927,62892,35395,23658,27429,22496,60550,36644,38050,79320,7934,30101,71573,14389,4701,31291,11384,39725,123530,44408,58972,95799,10389,46232,3432,40560,35984,4665,169950,111402,18065,21540,70358,51973,26344,101435,5668,28783,6701,64979,30591,53626,89555,54550,47720,72312,32532,81224,32367,12856,45452,23288,68436,11028,48698,59988,25334,12898,76129,76496,66076,28330,66192,34221,24405,81851,52335,38502,25430,29421,7258,23734,12534,60625,23697,17543,35830,5033,17253,27189,48127,91649,58796,46586,42569,40202,70022,3922,41658,66536,67928,13621,71191,63947,89954,7543,20366,73226,55216,63823,20147,28646,62441,10910,21883,40687,5770,12349,59303,82027,45440,12710,126532,87569,69111,27004,13098,37670,125784,37616,46404,36971,20823,44255,53184,53752,9362,16464,13631,24283,57198,27205,60289,35590,21193,59034,71649,40198,22347,37446,30613,39731,23986,65414,6705,23140,42971,9792,23886,16397,17598,42024,32014,78351,31432,3978,34883,19845,10204,56595,25611,58573,31771,60213,24678,85938,22206,27750,43462,24977,22131,65617,70257,71995,75183,106608,54436,44381,61439,41163,81099,34095,36953,14703,23992,105384,20334,34145,48786,72804,71943,32757,77178,6381,77041,85234,31634,62231,7004,66194,23721,18122,82066,43339,13417,28110,26647,11703,160005,55765,78251,35519,22708,66840,6126,37952,31632,55294,13842,57847,43009,57445,41641,13437,41892,8126,55609,71439,65768,3032,12225,16758,12150,110890,58822,80581,12690,69074,49169,118185,9745,24482,35611,21100,13245,25269,26177,60738,119320,13615,120677,36560,14048,16249,73591,11789,42419,8691,44373,5698,38758,39244,36214,7654,26381,42371,42425,5167,38173,28250,11362,41671,38101,22759,29654,16846,42528,32035,51949,34841,65641,94153,55081,42157,53629,5482,6064,33333,53055,38653,54655,25486,28830,18681,38431,89032,38939,44533,44382,7073,93080,39698,68653,14900,4180,26923,27360,30629,33018,23166,4915,50098,31775,14625,48831,53413,50677,16354,24128,49869,23038,53312,43846,11263,19507,11322,86895,60729,144564,33429,36964,4437,48013,39779,71605,45697,20501,3059,39338,3228,22719,37974,72431,8486,24363,19558,64046,35799,20259,79873,13544,36404,55886,13904,42955,43750,17743,107390,86058,40137,65042,29084,8999,6357,29914,45867,75705,19543,64725,60567,58452,5015,50256,60877,91907,42209,13678,7797,23545,65227,86909,18614,12483,34314,52497,28754,112096,30756,16519,18075,9958,14076,16114,5200,40241,14275,53117,50561,27253,3998,85851,32716,44901,40698,42272,67106,73621,23828,50619,64147,89432,67240,119266,15347,50315,39374,27347,21786,7037,33320,9277,14225,25474,50546,61235,64796,38341,46464,38388,53785,8315,29782,35079,5943,9616,73662,52409,28236,40773,84419,49739,8678,46548,16583,15864,5920,42891,6635,91882,54534,32013,105413,11681,18153,98213,60754,53642,40221,43931,60076,9481,17046,26098,22609,21386,2797,11266,59378,57464,46271,10182,53724,89160,33549,19557,8022,43213,62795,42025,74820,49326,55701,65268,49257,38526,47121,32407,100592,21980,10691,10664,13298,58489,81011,24481,30354,5334,11554,62781,80241,17457,13682,12911,32340,54094,4987,15562,19126,58105,62497,34333,74015,78119,27715,20098,37580,14200,24208,36266,68885,66174,3965,143792,35892,43824,14009,7294,69932,11540,31644,55554,6756,69754,65940,26128,88712,11048,14382,34369,3908,30339,9290,22745,49669,93604,62655,50036,60244,52406,44821,37915,4894,38413,44612,19168,26668,20326,45231,12448,35082,121782,4863,7291,24332,42551,28462,67887,21226,41026,137990,53668,40922,15485,21118,118903,77715,24519,58873,61054,25674,2960,30624,103189,48284,40536,56053,37084,50773,11615,83270,4311,30367,6372,56358,14518,10602,35857,93798,51500,69148,51610,27676,16157,92788,4395,23687,11944,57418,71058,37037,23290,34201,84364,68400,24135,18615,15050,113480,83720,52761,26031,43187,11278,3710,27465,97386,3393,65371,5707,106125,46278,12099,17823,39132,34422])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf54571e-d33e-48d3-8014-bd4e8c8d6ae9",
   "metadata": {},
   "source": [
    "Example 3 -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c325a9-1209-4d08-ab66-009fb2d95f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset consists of life-expectancy data \n",
    "life_expectancy = np.array([52, 61, 58, 75, 74, 77, 58, 74, 54, 65, 67, 75, 74, 70, 36, 65, 35,55, 64, 28, 46, 52, 75, 42, 64, 75, 44, 65, 58, 65, 45, 73, 79, 48,55, 65, 53, 66, 56, 40, 76, 52, 77, 63, 74, 53, 22, 43, 33, 75, 60,58, 44, 69, 73, 36, 74, 72, 65, 56, 67, 68, 56, 67, 62, 59, 68, 53,59, 61, 59, 77, 76, 70, 78, 74, 64, 15, 42, 65, 70, 65, 64, 67, 65,66, 25, 65, 63, 75, 78, 63, 81, 80, 82, 66, 42, 26, 64, 72, 59, 78,69, 73, 79, 65, 60, 39, 64, 44, 77, 74, 42, 13, 73, 64, 65, 75, 78,72, 49, 75, 65, 59, 40, 70, 31, 58, 61, 79, 56, 67, 79, 61, 48, 68,52, 79, 70, 70, 59, 53, 75, 63, 31, 25, 63, 79, 60, 77, 77, 64, 33,52, 64, 40, 59, 80, 36, 64, 61, 54, 73, 21, 67, 45, 77, 78, 56, 32,81, 69, 82, 33, 16, 41, 79, 34, 77, 71, 74, 73, 44, 33, 59, 74, 43,67, 63, 73, 58, 59, 65, 55, 64, 76, 71, 60, 79, 76, 62, 50, 42, 72,60, 77, 44, 72, 54, 58, 56, 40, 61, 25, 47, 66, 74, 79, 62, 69, 22,67, 71, 40, 74, 80, 45, 68, 64, 55, 48, 52, 48, 49, 60, 62, 57, 23,67, 72, 76, 69, 56, 67, 58, 40, 78, 50, 53, 73, 66, 69, 73, 73, 37,60, 65, 60, 60, 68, 50, 33, 68, 24, 79, 52, 78, 30, 58, 81, 72, 79,75, 52, 51, 74, 66, 65, 41, 53, 57, 76, 63, 64, 48, 48, 77, 52, 60,61, 52, 39, 71, 26, 54, 68, 77, 64, 67, 62, 40, 67, 66, 47, 33, 69,74, 76, 62, 69, 54, 67, 33, 71, 56, 41, 79, 37, 64, 37, 70, 49, 60,74, 79, 65, 79, 79, 75, 78, 72, 76, 31, 70, 24, 59, 28, 78, 61, 75,40, 51, 74, 53, 72, 71, 55, 67, 39, 60, 67, 60, 72, 81, 75, 52, 63,66, 38, 57, 58, 71, 40, 72, 70,  6, 81, 41, 79, 46, 28, 48, 50, 65,76, 75, 32, 75, 70, 46, 73, 61, 48, 55, 41, 52, 48, 53, 62, 65, 69,18, 79, 78, 66, 65, 72, 65, 69, 69, 75, 83, 62, 78, 51, 46, 47, 46,82, 76, 64, 54, 72, 62, 47, 59, 63, 72, 55, 63, 78, 68, 73, 82, 61,47, 52, 78, 75, 42, 53, 65, 60, 48, 59, 52, 58, 76, 63, 76, 58, 67,40, 69, 74, 48, 60, 56, 75, 75, 54, 26, 50, 67, 59, 50, 70, 70, 62,38, 42, 63, 39, 72, 63, 42, 79, 69, 53, 59, 72, 75, 65, 37, 71, 39,43, 64, 84, 75, 80, 54, 66, 44, 60, 72, 73, 50, 62, 62, 58, 42, 61,80, 55, 73, 59, 60, 67, 50, 64, 74, 58, 73, 60, 57, 30, 70, 72, 63,54, 77, 56, 53, 73, 49, 75, 49, 47, 71, 77, 19, 77, 72, 63, 49, 67,65, 47, 71, 77, 71, 71, 53, 78, 76, 67, 65, 61, 60, 21, 60, 59, 68,43, 64, 76, 59, 72, 64, 38, 61, 65, 77, 64, 52, 78, 80, 35, 37, 80,58, 62, 71, 23, 67, 39, 67, 62, 52, 49, 61, 76, 66, 59, 42, 68, 75,60, 52, 73, 60, 70, 62, 74, 74, 61, 51, 23,  2, 39, 69, 52, 40, 46,72, 82, 77, 71, 82, 75, 77, 37, 52, 53, 70, 69, 65, 29, 54, 55, 55,75, 62, 46, 66, 77, 75, 73, 77, 71, 72, 77, 55, 51, 58, 66, 58, 80,75, 47, 78, 59, 66, 30, 76, 63, 57, 29, 53, 78, 71, 48, 58, 45, 59,63, 46, 68, 73, 69, 42, 63, 76, 59, 61, 65, 55, 70, 68, 38, 21, 64,71, 74, 77, 61, 67, 73, 78, 49, 31, 46, 64, 72, 33, 68, 76, 82, 59,59, 52, 66, 63, 11, 61, 74, 60, 61, 73, 54, 70, 45, 42, 58, 73, 36,82, 75, 51, 79, 58, 59, 68,  0, 78, 52, 61, 65, 73, 46, 81, 63, 27,82, 68, 80, 61, 79, 69, 42, 66, 52, 45, 62, 27, 76, 62, 64, 67, 43,51, 71, 77, 43, 24, 53, 52, 36, 52, 76, 69, 65, 73, 62, 68, 70, 75,70, 48, 58, 56, 66, 55, 62, 77, 62, 65, 51, 70, 60, 76, 74, 65, 72,62, 72, 42, 41, 43, 77, 68, 76, 76, 72, 56, 80, 77, 66, 57,  5, 72,67, 78, 81, 77, 66, 35, 54, 37, 42, 71, 78, 66, 68, 33, 25, 54,  8,72, 63, 38, 45, 67, 56, 64, 36, 54, 70, 71, 64, 72, 57, 59, 66, 51,77, 72, 36, 71, 70, 80, 39, 72, 74, 50, 58, 79, 25, 35, 61, 63, 50,68, 60, 82, 58, 14, 32, 77, 70, 65, 81, 73, 48, 67, 67, 30, 69, 69,59, 67, 74, 46, 53, 64, 75, 67, 54, 75, 61, 67, 19, 30, 62, 70, 76,47, 70, 73, 34, 57, 71, 56, 68, 44, 38, 47, 66, 72, 46, 68, 72, 44,58, 42, 62, 79, 45, 75, 37, 44, 24, 78, 52, 40, 75, 45, 52, 34, 74,82,  6, 78, 70, 36, 42, 75, 58, 20,  4, 53, 57, 69, 71, 53, 61, 26,67, 60, 76, 44, 68, 78, 80, 76, 55, 66, 67, 69, 71, 58, 69, 42, 53,35, 74, 56, 59, 41, 71, 64, 49, 68, 58, 69, 52, 75, 47, 77, 63, 53,42, 44, 72, 60, 59, 55, 57, 35, 78, 66, 73, 61, 47, 74, 75, 71, 45,43, 60, 53, 54, 79, 69, 46, 57, 64, 58, 36, 51, 77, 64, 72, 64, 44,54, 69, 59, 54, 58, 59, 68, 58, 75, 73, 62, 78, 51, 60])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc299f4-b34c-45a0-b0f1-8d3db56a8fec",
   "metadata": {},
   "source": [
    "### Handling Null/Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5511abe-fae8-43f5-8e6b-1bbc13419fc5",
   "metadata": {},
   "source": [
    "- Deletion:\n",
    "    - Listwise Deletion: Remove entire rows containing null values.\n",
    "    - Pairwise Deletion: Analyze data based on available pairs of variables, ignoring rows with null values in other variables.\n",
    "- Imputation:\n",
    "    - Mean/Median/Mode Imputation: Replace null values with the mean, median, or mode of the respective column.\n",
    "    - Forward Fill/Backward Fill: Fill null values with the preceding or succeeding non-null value in the same column.\n",
    "    - Linear Interpolation: Interpolate null values using linear interpolation based on neighboring data points.\n",
    "    - K-Nearest Neighbors (KNN) Imputation: Use the values of nearest neighbors to impute null values.\n",
    "    - Random Imputation: Replace null values with random values from the same column's distribution.\n",
    "- Bucketing: Group data into buckets or categories and treat null values as a separate category."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf0f7f4-993c-40ed-b7c7-efdc3dee7e8c",
   "metadata": {},
   "source": [
    "###### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abce8f4-f345-4f4f-93b0-a9356e99cf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.DataFrame( {\n",
    "    \"Date\" : np.arange(\"2024-01-01\", \"2024-04-01\", dtype=\"datetime64[D]\"),\n",
    "    \"Driving Hours\" : [ 4.,  2.,  4.,  3.,  3.,  3.,  1.,  4.,  2.,  2.,  4.,  2.,  1., 3.,  3.,  3.,  5.,  2.,  3.,  4.,  5.,  1.,  1.,  3.,  3.,  2.,  3., 3.,  2.,  2.,  2.,  3.,  2.,  3.,  4.,  2.,  3.,  3.,  2.,  3.,2.,  4.,  2., np.nan,  2., np.nan,  3., np.nan,  1., np.nan,  3., np.nan,  2.,np.nan,  2., np.nan,  3., np.nan,  4., np.nan,  2., np.nan,  1., np.nan,  3., np.nan,3., np.nan,  2., np.nan,  5., np.nan,  3., np.nan,  3., np.nan,  3., np.nan,  3.,np.nan,  2., np.nan,  2., np.nan,  3.,  5.,  4.,  2.,  4.,  4.,  3.]\n",
    "    })\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0642b895-7ab4-445b-80b2-58d0f98aa37a",
   "metadata": {},
   "source": [
    "#### Using fillna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1f1d33-14f2-4df6-8dfe-eccc59a3377d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4e38e158-56b2-44b3-9aeb-8bb5112309dc",
   "metadata": {},
   "source": [
    "#### Using Linear Interpolation/Extrapolation\n",
    "**Interpolation**\n",
    "- Definition: Interpolation is the process of estimating unknown values within the range of a set of known data points. It’s like \"filling in the gaps\" in between known data points.\n",
    "- Use case: If you have data points for January and March, interpolation would estimate the value for February.\n",
    "\n",
    "**Extrapolation**\n",
    "- Definition: Extrapolation is the process of estimating values outside the range of known data points. It’s an attempt to predict what might happen beyond the data you've observed.\n",
    "- Use case: If you have data for January through March and want to estimate the value for April, extrapolation would help with that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f821fddf-f2c4-4738-b41a-1a6383246e2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "014cb95c-5f61-428f-80f3-036374af85bf",
   "metadata": {},
   "source": [
    "#### Using Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed7e9a4-9f90-4c8a-b54b-6e06a4d55d5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac096eb1-d8bd-4c37-bfb3-9352e8fdee07",
   "metadata": {},
   "source": [
    "### Handling Outliers - "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a952a3-394a-44db-9c57-056e62c978cd",
   "metadata": {},
   "source": [
    "#### `Z-Score Method:`\n",
    "\n",
    "- The z-score method involves calculating the z-score for each data point, which represents the number of standard deviations away from the mean.\n",
    "Data points with z-scores beyond a certain threshold (e.g., |z-score| > 3) are considered outliers and can be removed or treated separately.\n",
    "The z-score method is sensitive to the mean and standard deviation of the data, and it assumes that the data is normally distributed.\n",
    "This method is useful when the data is approximately normally distributed and when the goal is to identify outliers based on their deviation from the mean.\n",
    "\n",
    "#### `IQR Method:`\n",
    "\n",
    "- The IQR method involves calculating the interquartile range (IQR), which is the difference between the third quartile (Q3) and the first quartile (Q1) of the data.\n",
    "Outliers are defined as data points that fall below Q1 - 1.5 * IQR or above Q3 + 1.5 * IQR.\n",
    "The IQR method is robust to outliers and does not assume any specific distribution of the data.\n",
    "This method is useful when the data is skewed or not normally distributed, as it focuses on the middle 50% of the data and is less influenced by extreme values.\n",
    "In general, if the data is approximately normally distributed and the goal is to identify outliers based on their deviation from the mean, the z-score method may be more appropriate. On the other hand, if the data is skewed or not normally distributed, or if the goal is to identify outliers based on their relative position within the dataset, the IQR method may be a better choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2035ef25-6a35-4b2e-8160-fd8282d2eba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries = np.array([29756,20014,20347,57214,41327,40209,93390,122004,17725,47210,44386,48407,16837,83731,9130,66723,72525,57347,10941,18726,8913,59251,13090,37983,134656,45499,59533,82998,31440,11672,16295,30676,21822,35263,27340,65522,23380,11662,7066,22403,41230,46693,22478,82491,7347,16263,72672,20522,38409,30175,31383,98820,13605,45096,12397,90988,6602,29786,102559,31790,29768,50085,22649,24426,4059,95210,68657,17799,37370,46160,35133,40969,57201,54757,17973,13610,46004,91341,24474,48005,9473,10277,71287,9383,36492,104352,13473,51293,51911,10026,39992,125885,44462,76531,41512,47267,33231,14180,44474,55702,39554,8359,51892,98574,43638,90568,40508,34129,98497,74784,63383,47197,83519,26458,38642,9629,18404,47324,15793,120345,61126,64613,57964,47582,77944,27082,51891,98126,69008,23284,49785,72406,56418,36769,58715,42999,47333,45733,141091,3848,57584,48356,95301,95269,49894,101380,44028,54577,71055,32066,26596,66653,3179,44484,62889,62952,50903,74656,50733,38180,59410,105003,73854,33579,150293,26348,6769,26315,53038,35766,50517,64714,27523,26867,46607,9882,60052,46653,42143,37371,14475,103629,55402,6149,65128,32861,27603,75553,35641,21457,106916,50369,37731,6473,73858,7716,21144,34340,27917,18150,49270,16344,84532,28616,18452,84678,17990,26463,13671,70005,26237,7245,16941,64383,3317,7275,26981,12600,36983,40054,7283,82140,65120,8259,44235,30682,68578,80737,14009,88942,48374,43148,11447,32203,67168,50149,8607,9680,35442,47306,67316,52503,89884,18337,11798,40659,90852,25479,4737,107231,40006,34020,61695,12128,14126,71024,42150,54591,93625,23809,9698,50910,75967,36494,53497,28006,16650,50352,42133,10915,50698,19962,30772,23430,75790,72083,162101,75728,60565,40074,58299,18280,128972,76801,38314,12744,25607,22188,31862,15955,31175,11044,44390,49677,33251,85617,81684,48054,63108,33461,39505,51449,47547,49199,152777,49820,23147,35010,44921,39633,16546,35436,32229,28603,31804,21668,102866,58514,140647,22149,26732,88552,77813,75665,38038,123394,9457,28241,52657,9075,148287,70362,27398,18672,19003,17600,114609,4318,19729,23148,32015,87090,5342,56550,38458,5400,50686,46353,14777,19302,16606,21645,37117,22488,5465,28650,57321,34736,43956,37151,9776,37461,17631,98557,18773,15927,62892,35395,23658,27429,22496,60550,36644,38050,79320,7934,30101,71573,14389,4701,31291,11384,39725,123530,44408,58972,95799,10389,46232,3432,40560,35984,4665,169950,111402,18065,21540,70358,51973,26344,101435,5668,28783,6701,64979,30591,53626,89555,54550,47720,72312,32532,81224,32367,12856,45452,23288,68436,11028,48698,59988,25334,12898,76129,76496,66076,28330,66192,34221,24405,81851,52335,38502,25430,29421,7258,23734,12534,60625,23697,17543,35830,5033,17253,27189,48127,91649,58796,46586,42569,40202,70022,3922,41658,66536,67928,13621,71191,63947,89954,7543,20366,73226,55216,63823,20147,28646,62441,10910,21883,40687,5770,12349,59303,82027,45440,12710,126532,87569,69111,27004,13098,37670,125784,37616,46404,36971,20823,44255,53184,53752,9362,16464,13631,24283,57198,27205,60289,35590,21193,59034,71649,40198,22347,37446,30613,39731,23986,65414,6705,23140,42971,9792,23886,16397,17598,42024,32014,78351,31432,3978,34883,19845,10204,56595,25611,58573,31771,60213,24678,85938,22206,27750,43462,24977,22131,65617,70257,71995,75183,106608,54436,44381,61439,41163,81099,34095,36953,14703,23992,105384,20334,34145,48786,72804,71943,32757,77178,6381,77041,85234,31634,62231,7004,66194,23721,18122,82066,43339,13417,28110,26647,11703,160005,55765,78251,35519,22708,66840,6126,37952,31632,55294,13842,57847,43009,57445,41641,13437,41892,8126,55609,71439,65768,3032,12225,16758,12150,110890,58822,80581,12690,69074,49169,118185,9745,24482,35611,21100,13245,25269,26177,60738,119320,13615,120677,36560,14048,16249,73591,11789,42419,8691,44373,5698,38758,39244,36214,7654,26381,42371,42425,5167,38173,28250,11362,41671,38101,22759,29654,16846,42528,32035,51949,34841,65641,94153,55081,42157,53629,5482,6064,33333,53055,38653,54655,25486,28830,18681,38431,89032,38939,44533,44382,7073,93080,39698,68653,14900,4180,26923,27360,30629,33018,23166,4915,50098,31775,14625,48831,53413,50677,16354,24128,49869,23038,53312,43846,11263,19507,11322,86895,60729,144564,33429,36964,4437,48013,39779,71605,45697,20501,3059,39338,3228,22719,37974,72431,8486,24363,19558,64046,35799,20259,79873,13544,36404,55886,13904,42955,43750,17743,107390,86058,40137,65042,29084,8999,6357,29914,45867,75705,19543,64725,60567,58452,5015,50256,60877,91907,42209,13678,7797,23545,65227,86909,18614,12483,34314,52497,28754,112096,30756,16519,18075,9958,14076,16114,5200,40241,14275,53117,50561,27253,3998,85851,32716,44901,40698,42272,67106,73621,23828,50619,64147,89432,67240,119266,15347,50315,39374,27347,21786,7037,33320,9277,14225,25474,50546,61235,64796,38341,46464,38388,53785,8315,29782,35079,5943,9616,73662,52409,28236,40773,84419,49739,8678,46548,16583,15864,5920,42891,6635,91882,54534,32013,105413,11681,18153,98213,60754,53642,40221,43931,60076,9481,17046,26098,22609,21386,2797,11266,59378,57464,46271,10182,53724,89160,33549,19557,8022,43213,62795,42025,74820,49326,55701,65268,49257,38526,47121,32407,100592,21980,10691,10664,13298,58489,81011,24481,30354,5334,11554,62781,80241,17457,13682,12911,32340,54094,4987,15562,19126,58105,62497,34333,74015,78119,27715,20098,37580,14200,24208,36266,68885,66174,3965,143792,35892,43824,14009,7294,69932,11540,31644,55554,6756,69754,65940,26128,88712,11048,14382,34369,3908,30339,9290,22745,49669,93604,62655,50036,60244,52406,44821,37915,4894,38413,44612,19168,26668,20326,45231,12448,35082,121782,4863,7291,24332,42551,28462,67887,21226,41026,137990,53668,40922,15485,21118,118903,77715,24519,58873,61054,25674,2960,30624,103189,48284,40536,56053,37084,50773,11615,83270,4311,30367,6372,56358,14518,10602,35857,93798,51500,69148,51610,27676,16157,92788,4395,23687,11944,57418,71058,37037,23290,34201,84364,68400,24135,18615,15050,113480,83720,52761,26031,43187,11278,3710,27465,97386,3393,65371,5707,106125,46278,12099,17823,39132,34422])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128ae0c2-9187-4a47-ac8a-025e3d05c9f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3486e7d9-23f8-45da-9d38-b30a9a372131",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aade7e5f-0950-438b-b0a5-f0b96632291f",
   "metadata": {},
   "source": [
    "<hr><hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6f6f2e-7392-4081-91a5-bf6526866894",
   "metadata": {},
   "source": [
    "## Introduction to Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b684580-f141-493d-908c-f96d45445e7e",
   "metadata": {},
   "source": [
    "Machine learning is a branch of artificial intelligence (AI) that focuses on the development of algorithms and statistical models that enable computers to learn and improve their performance on a specific task or problem without being explicitly programmed. In essence, it involves creating and training models that can learn from data and make predictions or decisions based on that data.\n",
    "\n",
    "The core idea behind machine learning is to use data to uncover patterns, relationships, and insights that can be used to make predictions or take actions. This is typically done through the following steps:\n",
    "\n",
    "1. Data Collection: Gathering relevant data from various sources, which may include structured data (e.g., databases) and unstructured data (e.g., text, images, videos).\n",
    "\n",
    "2. Data Preprocessing: Cleaning, transforming, and preparing the data for analysis. This may involve tasks such as handling missing values, encoding categorical variables, and scaling numerical features.\n",
    "\n",
    "3. Model Training: Selecting an appropriate machine learning algorithm and training a model on the prepared data. During training, the model learns patterns and relationships in the data by adjusting its internal parameters.\n",
    "\n",
    "4. Model Evaluation: Assessing the performance of the trained model using evaluation metrics and validation techniques. This helps determine how well the model generalizes to new, unseen data.\n",
    "\n",
    "5. Model Deployment: Deploying the trained model to make predictions or decisions on new, real-world data. This may involve integrating the model into existing systems or applications.\n",
    "\n",
    "\n",
    "\n",
    "### Machine learning Categories:\n",
    "\n",
    "- Supervised Learning: In supervised learning, the model is trained on labeled data, where each example in the training dataset is associated with a target label or output. The goal is to learn a mapping from input features to output labels, allowing the model to make predictions on new, unseen data.\n",
    "\n",
    "- Unsupervised Learning: In unsupervised learning, the model is trained on unlabeled data, and the goal is to uncover hidden patterns or structures in the data. This may involve tasks such as clustering similar data points together or dimensionality reduction.\n",
    "\n",
    "- Reinforcement Learning: In reinforcement learning, the model learns to make decisions by interacting with an environment and receiving feedback or rewards. The goal is to learn a policy that maximizes the cumulative reward over time.\n",
    "\n",
    "### Types of Supervised Learning\n",
    "\n",
    "- Classification: Classification is a type of supervised learning where the goal is to predict the categorical class labels of new instances based on past observations. In classification, the output variable is discrete and belongs to a specific class or category. Some common classification algorithms include:\r\n",
    "\r\n",
    "\t- Logistic Regression\r\n",
    "\t- Decision Trees\r\n",
    "\t- Random Forest\r\n",
    "\t- Support Vector Machines (SVM)\r\n",
    "\t- k-Nearest Neighbors (k-NN)\r\n",
    "\t- Naive Bayes\r\n",
    "\r\n",
    "- Regression: Regression is another type of supervised learning where the goal is to predict continuous numerical values based on input features. In regression, the output variable is continuous and can take any value within a range. Some common regression algorithms include:\r\n",
    "\r\n",
    "\t- Linear Regression\r\n",
    "\t- Polynomial Regression\r\n",
    "\t- Ridge Regression\r\n",
    "\t- Lasso Regression\r\n",
    "\t- Support Vector Regression (SVR)\r\n",
    "\t- Decision Tree Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e70858-afc1-4d5b-9154-b275a7b0abf7",
   "metadata": {},
   "source": [
    "## Linear Regression Example"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "147b486b-d6ef-4007-a584-dc2088440a20",
   "metadata": {},
   "source": [
    "- Linear regression is a statistical method used for modeling the relationship between a dependent variable (target variable) and one or more independent variables (predictor variables).\n",
    "- It is a supervised learning algorithm because it learns from labeled data, where the input features and their corresponding target values are provided during training.\n",
    "- In linear regression, the goal is to fit a linear equation to the data that best describes the relationship between the independent variables and the dependent variable. \n",
    "\n",
    "#### Assumptions of Linear Regression\n",
    "\n",
    "\n",
    "- `Linearity:` The relationship between the independent variables and the dependent variable should be linear. This means that the change in the dependent variable is proportional to the change in the independent variable\n",
    "  s.\n",
    "- `Independence of errors:` The errors (residuals) should be independent of each other. In other words, the error term for one observation should not be correlated with the error term for another observa  on.\n",
    "- `Constant Variance:` The variance of the errors should be constant across all values of the independent variables. This means that the spread of the residuals should be the same at all levels of the independent variab\n",
    "  les.\n",
    "- `Normality of residuals:` The residuals should be normally distributed. This means that the distribution of the residuals should be symmetric around zero, with the majority of residuals clustered near zero and fewer residuals further away from \n",
    "  zero.\n",
    "- `No perfect multicollinearity:` There should be no perfect linear relationship among the independent variables. This means that the independent variables should not be highly correlated with each \n",
    "  other.\n",
    "- `No outliers:` There should be no outliers in the data that can unduly influence the estimation of the regression coeffi\n",
    "  cients.\n",
    "- `Additivity:` The effect of changes in the independent variables on the dependent variable is additive. This means that the effect of changing one independent variable is independent of the values of the other independent variables.t variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fb1e45-2725-4d6a-9361-6e409e1aee9b",
   "metadata": {},
   "source": [
    "### Housing Data Case Study\n",
    "\n",
    "#### Problem Statement:\n",
    "\n",
    "Consider a real estate company that has a dataset containing the prices of properties in the Mumbai region. It wishes to use the data to optimize the sale prices of the properties based on important factors such as area, bedrooms, parking, etc.\n",
    "\n",
    "Essentially, the company wants —\n",
    "\n",
    "- To identify the variables affecting house prices, e.g. area, number of rooms, bathrooms, etc.\n",
    "\n",
    "- To create a linear model that quantitatively relates house prices with variables such as number of rooms, area, number of bathrooms, etc.\n",
    "\n",
    "- To know the accuracy of the model, i.e. how well these variables can predict house prices.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06edd94a-6d0d-4795-92e3-326315da13ae",
   "metadata": {},
   "source": [
    "#### Reading and Understanding the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d752af-782b-46b1-90c1-70c363ac663e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the basic packages\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "\n",
    "%matplotlib inline\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "plt.rcParams['figure.figsize'] = (4, 3)\n",
    "# plt.rcParams['font.size'] = 10\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df = pd.read_csv(\"Housing.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f66748f-76a3-47b0-9812-835258fd7f6f",
   "metadata": {},
   "source": [
    "#### Handling Nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9888127-ba31-4ae6-9ae9-0fd858f9f5e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e3b4b2b-9308-45a3-ac62-ca36caf7f9f6",
   "metadata": {},
   "source": [
    "#### Outlier Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5d3c34-e38a-47a5-ab22-8c287b482c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outliers(col, axes = None) :\n",
    "    \"\"\"Plots histogram and boxplots and returns min whisker and max whisker values\"\"\"\n",
    "    sns.histplot(col, kde = True, ax = axes)\n",
    "    sns.boxplot(col, ax = axes)\n",
    "    IQR_factor = (np.percentile(col, 75) - np.percentile(col, 25)) * 1.5\n",
    "    return (np.percentile(col, 25) - IQR_factor), (np.percentile(col, 75) + IQR_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ca6ab3-01eb-4c79-9095-8f60b09cc43b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "efdce3dc-eb87-433a-b092-ed02be94a4ed",
   "metadata": {},
   "source": [
    "### Encoding Techniques\r\n",
    "\r\n",
    "Converting categorical variables to numeric variables is called \"encoding\" or \"categorical encoding.\" This process involves transforming categorical data, which represents categories or labels, into numerical values that can be used in machine learning models.\r\n",
    "\r\n",
    "There are several methods for encoding categorical variables into numerical format, including:\r\n",
    "\r\n",
    "- `Ordinal Encoding:` Assigns a unique integer to each category based on the order or ranking of the categories.\r\n",
    "\r\n",
    "- `One-Hot Encoding:` Creates binary columns for each category, where each column represents whether a sample belongs to that category or not (1 or 0).\r\n",
    "\r\n",
    "- `Label Encoding:` Encodes target labels with values between 0 and n_that category."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fcf1d7-df88-4e65-96e8-e616dc930534",
   "metadata": {},
   "source": [
    "###### Encoding column hotwaterheating using map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272dede1-30b4-4d0e-afd2-3fa80c5c95ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hotwaterheating = df.hotwaterheating.map({\"yes\" : 1, \"no\" : 2})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90066e62-2c0b-4359-b049-96dcaf9f7f42",
   "metadata": {},
   "source": [
    "#### OneHotEncoding\n",
    "\n",
    "- OneHotEncoder is a preprocessing technique used in machine learning to convert categorical variables into a one-hot encoded representation.\n",
    "- In many machine learning algorithms, categorical variables cannot be directly used as input, as they are non-numeric and don't have an inherent order or magnitude. One way to handle categorical variables is to convert them into a numerical representation that can be fed into machine learning models.\n",
    "- The one-hot encoding technique converts categorical variables into a binary matrix, where each category is represented by a binary vector of length equal to the number of unique categories in the variable. In this binary matrix, each column represents a category, and each row corresponds to an observation.\n",
    "- For each observation, the value is 1 in the column corresponding to the category of that observation, and 0 in all other columns. This ensures that the numerical representation is not biased by the original categorical values and preserves the categorical nature of the variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d201b4-0267-432f-8789-73707f05b67b",
   "metadata": {},
   "source": [
    "###### Ecoding furnishingstatus using OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72395ed-2659-40e5-9bdc-5c68e408548f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "# encoded_data = encoder.fit_transform(df.furnishingstatus.to_frame())\n",
    "\n",
    "data = pd.DataFrame(encoded_data.toarray().astype(int), columns=['Unfurnished', 'Semi-furnished', 'Furnished'])\n",
    "\n",
    "df = pd.concat((df, data), axis=1)\n",
    "df.drop(columns=\"furnishingstatus\", inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04d1322-01cb-4869-b1f0-a5367686efcf",
   "metadata": {},
   "source": [
    "#### pd.getdummies()\n",
    "\n",
    "`pd.get_dummies()` performs the following steps:\n",
    "\n",
    "- Identifies categorical variables in the input data.\n",
    "- Creates binary columns for each unique category in each categorical variable.\n",
    "- Assigns a value of 1 to the appropriate column for each observation based on its category, and 0 to all other columns.\n",
    "\n",
    "This function is useful for quickly converting categorical variables into a format suitable for machine learning algorithms that require numerical input. It's commonly used during data preprocessing and feature engineering steps in data analysis and machine learning workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a5a553-70f5-4855-b7a5-6468d964f2b6",
   "metadata": {},
   "source": [
    "###### Ecoding furnishingstatus using pd.getdummies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d418825c-4d2c-4580-b738-36b1c1cb13f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(data=df, columns=[\"furnishingstatus\"], dtype=int)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b227790a-7307-4db3-8791-8faaae60a4bd",
   "metadata": {},
   "source": [
    "### Scaling of Numerical Variables\n",
    "\n",
    "#### Standardization (Z-score normalization):\n",
    "\n",
    "- Standardization scales the features so that they have a mean of 0 and a standard deviation of 1.\n",
    "- It subtracts the mean of the feature and then divides by the standard deviation.\n",
    "- This method assumes that the data follows a Gaussian distribution (normal distribution).\n",
    "- Standardization is less affected by outliers compared to min-max scaling.\n",
    "\n",
    "#### Min-Max Scaling:\n",
    "\n",
    "- Min-Max scaling scales the features to a fixed range, typically [0, 1].\n",
    "- It subtracts the minimum value of the feature and then divides by the range (maximum value minus minimum value).\n",
    "- Min-Max scaling preserves the shape of the original distribution and is used when the algorithm does not assume a normal distribution of the features. However, it is sensitive to outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6004ff02-757e-420f-a0a9-a5bcabcaccb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "df = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0698a0-5183-4123-a192-7fe702f8dff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# background process\n",
    "(131904400 - df.price.min()) / (df.price.max() - df.price.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c174017f-ecc4-4aef-841a-6fc4bb1099bf",
   "metadata": {},
   "source": [
    "### Multicolinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566df828-0ea7-4c76-b6f6-9e1e82d73645",
   "metadata": {},
   "source": [
    "- Multicollinearity exists when there is a correlation between multiple independent variables in a multiple regression model.\n",
    "-  When two variables have a correlation coefficient of either +1.0 or -1.0, they are considered perfectly collinear.\r",
    "- \n",
    "The presence of multicollinearity among independent variables can lead to less dependable statistical conclusions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ca6d9d-22bc-4ba9-b4b3-d9d2b7e5a1de",
   "metadata": {},
   "source": [
    "#### Pair Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49d8659-26d1-4a04-9dcc-d368fbc16f6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "53518761-592f-481d-8b66-a15a00bb2421",
   "metadata": {},
   "source": [
    "#### Correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84af962d-7210-4ba6-9e08-5d1a1523cd35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30bd3285-bf4a-4799-9f69-7945ec293cdf",
   "metadata": {},
   "source": [
    "#### Heat Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae941fc9-8d9a-441d-a0c5-8a0f88e76adf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "96035311-3522-493e-b696-058b313bbaa8",
   "metadata": {},
   "source": [
    "#### Variance Inflation Factor (VIF) Thresholding:\n",
    "- A variance inflation factor (VIF) is a measure of the amount of multicollinearity in regression analysis.\n",
    "- VIF determines the strength of the correlation between the independent variables. \n",
    "- It is predicted by taking a variable and regressing it against every other variable. \n",
    "- VIF score of an independent variable represents how well the variable is explained by other independent variables.\n",
    "- R^2 value is determined to find out how well an independent variable is described by the other independent variables. A high value of R^2 means that the variable is highly correlated with the other variables.\n",
    "- Set a threshold for VIF values and remove predictor variables with VIF values exceeding the threshold.\n",
    "    - `VIF < 5: Low multicollinearity.` The variance of the estimated regression coefficient is moderately affected by multicollinearity.\n",
    "    - `5 ≤ VIF < 10: Moderate multicollinearity.` The variance of the estimated regression coefficient is significantly affected by multicollinearity.\n",
    "    - `VIF ≥ 10: High multicollinearity.` The variance of the estimated regression coefficient is highly affected by multicollinearity, and the coefficient may be unreliable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6ca982-287c-4d69-a7ad-0d08c3095541",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "features = df.drop(columns=[\"price\"])\n",
    "features = api.add_constant(features)\n",
    "\n",
    "vif_result = pd.DataFrame()\n",
    "vif_result[\"Variable\"] = features.columns\n",
    "vif_result[\"VIF value\"] = [variance_inflation_factor(features.values, i) for i in range(features.shape[1])] \n",
    "vif_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3253d213-39ea-426c-bfdd-468c6cd9cc05",
   "metadata": {},
   "source": [
    "### Building and Evaluating Linear Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b8c81a-6bf2-4996-a9c0-d61929dc0a57",
   "metadata": {},
   "source": [
    "- We have labelled data thus using supervised ML \n",
    "- Labeled data is continious thus using Regression Algorithm\n",
    "- There is linear correlation between features and label and thus using Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d92264-2f69-4d11-b5f3-c0cbe5b513fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.drop(columns=[\"price\"])\n",
    "label = df.price"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2435bbd6-0147-4ec7-bc97-5437a3f3de53",
   "metadata": {},
   "source": [
    "#### 1. Split data into test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d60b8f-632d-4747-8755-543d8dae8ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, label, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b556435-f6fb-4ae4-b2fe-e3c6bfd8af8a",
   "metadata": {},
   "source": [
    "#### 2. Fit Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502d81fc-f2a8-46af-8ffa-6d5ad66ea519",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762624a1-28db-434a-a62f-c58c43af80c8",
   "metadata": {},
   "source": [
    "#### 3. Predict y values using test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a98208-849c-4ee1-ac6a-b5d4da223ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2b0d34-a847-4e32-a9fe-3e63566cebf4",
   "metadata": {},
   "source": [
    "#### 4. Model Evaluaion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1083ef-9fd8-4168-9c45-829c99752ab3",
   "metadata": {},
   "source": [
    "Evaluating a linear regression model involves assessing how well it performs in predicting the target variable based on the input features. Here are some commonly used evaluation metrics for linear regression:\n",
    "\n",
    " **1. Mean Absolute Error (MAE):**\n",
    "    MAE measures the average absolute difference between the observed values and the predicted values. It is less sensitive to outliers compared to MSE.\n",
    "\n",
    " **2. Mean Squared Error (MSE):**\n",
    "    MSE measures the average squared difference between the observed values and the predicted values. It gives higher weight to large errors.\n",
    "\n",
    " **3. Root Mean Squared Error (RMSE):**\n",
    "\tRMSE is the square root of the MSE. It provides an interpretable measure of the average magnitude of the errors in the same units as the target variable.\n",
    "\t\n",
    " **4. R-squared (R2) Score:**\n",
    "\tR2 score measures the proportion of the variance in the dependent variable that is predictable from the independent variables. It ranges from 0 to 1, with higher values indicating a better fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67558bfb-3b2b-417f-862c-e1706bc567de",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\"Predicted\" : y_pred, \"Actual\" : y_test}).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0389342b-d108-472f-8156-632b767a3187",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, root_mean_squared_error, r2_score\n",
    "\n",
    "print(\"MAE - \", mean_absolute_error(y_test, y_pred))\n",
    "print(\"MSE - \", mean_squared_error(y_test, y_pred))\n",
    "print(\"RMSE - \", root_mean_squared_error(y_test, y_pred))\n",
    "print(\"R-sqaured - \", r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ce1a3a-1b07-4a5e-a832-85955761d771",
   "metadata": {},
   "source": [
    "#### Residual Analysis\n",
    "\n",
    "- Residual analysis is a statistical technique used to assess the quality of a regression model by examining the differences between the observed values of the dependent variable and the values predicted by the model (i.e., the residuals).\n",
    "- Residuals are the vertical distances between the observed data points and the regression line or surface.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d4429a-44fa-41ef-b2a8-52a413d10679",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = y_test - y_pred\n",
    "sns.histplot(residuals, kde = True)\n",
    "plt.axvline(residuals.mean(), color = \"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d3c1e1-7e97-40d1-a51b-443e2c21321e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a31002-87fd-446a-b2bb-856cd54ebda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.skew(residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a49a324-5a98-41b7-8ffb-39c13d27a6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.kurtosis(residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bb6c5e-0b51-4fcc-89ad-cab70d4c42a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "IQR_factor = (np.percentile(residuals, 75) - np.percentile(residuals, 25)) * 1.5\n",
    "min_w, max_w = (np.percentile(residuals, 25) - IQR_factor), (np.percentile(residuals, 75) + IQR_factor)\n",
    "residuals[np.logical_or(residuals<min_w, residuals>max_w)].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26f01bd-f891-45b3-b10b-cca78e04cb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features_rfe\n",
    "label = df.price"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ad4db2-9c54-41ab-b623-b764bcb61348",
   "metadata": {},
   "source": [
    "<hr><hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310de9fb-b162-410e-b484-2939c23643b3",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "- Logistic Regression is a statistical method used for modeling the probability of a binary outcome or a categorical outcome with more than two categories.\n",
    "- In logistic regression, the dependent variable (or target variable) is binary, meaning it can take only two possible outcomes, typically coded as 0 and 1 (e.g., \"yes\" or \"no\", \"success\" or \"failure\", \"positive\" or \"negative\").\n",
    "- The goal of logistic regression is to model the probability that the dependent variable belongs to a particular category as a function of one or more independent variables (or features).\n",
    "\n",
    "#### Assumptions\n",
    "\n",
    "- Binary Dependent Variable: Logistic regression assumes that the dependent variable (or target variable) is binary, meaning it has only two possible outcomes (e.g., 0 or 1, \"yes\" or \"no\").\r\n",
    "\r\n",
    "- Independence of Observations: Logistic regression assumes that the observations (data points) are independent of each other. In other words, the probability of one observation belonging to a particular category does not depend on the outcomes of other observations.\r\n",
    "\r\n",
    "- Linearity of Independent Variables and Log-Odds: Logistic regression assumes that the relationship between the independent variables and the log-odds of the dependent variable is linear. This means that the log-odds of the dependent variable are a linear combination of the independent variables after applying the logistic transformation.\r\n",
    "\r\n",
    "- No Multicollinearity: Logistic regression assumes that there is little or no multicollinearity among the independent variables. Multicollinearity occurs when two or more independent variables are highly correlated with each other, which can make it difficult to estimate the coefficients accurately.\r\n",
    "\r\n",
    "- Absence of Outliers: Logistic regression is sensitive to outliers, which are data points that significantly deviate from the overall pattern of the data. Outliers can influence the estimated coefficients and affect the model's predictions.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412dfc64-6900-4ac3-9058-bb2954f14f36",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f1065c-6c79-4cbb-b384-ee717a92c32b",
   "metadata": {},
   "source": [
    "#### Reading data from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c3e3ca-6625-4724-9a15-a443aabe7957",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Credit Default.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef1f85d-8efa-43ef-bf24-be549f2f2dee",
   "metadata": {},
   "source": [
    "#### Handling Nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a306e6a-f7f4-461f-985d-7890d8a88f24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88988106-8ab3-4ed7-95f6-59a31831b485",
   "metadata": {},
   "source": [
    "#### Handlilng Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979dc1e5-f172-4559-8131-b0cc6cb7e44b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "95083c8c-333c-42ea-a880-d6cb9c404808",
   "metadata": {},
   "source": [
    "#### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e36ab24-7e0a-4eed-bac1-03d7c332b6e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c3b2a648-6248-4305-be4d-fe3ecfe17c71",
   "metadata": {},
   "source": [
    "#### Checking for Linearity and Multicolinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256fc840-b8bc-4650-bcb1-bc8e918c79a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr(method=\"spearman\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2c3786-6e8f-4365-8f0a-c4999cca6d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.corr(method=\"spearman\"), annot=True, cmap=\"RdYlGn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b08351-4c0e-4418-86ed-57a2cf88a276",
   "metadata": {},
   "source": [
    "#### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46815120-cef7-4a0f-aa06-c25ca76da186",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62330f27-1b71-428e-b44b-33d51bf709fb",
   "metadata": {},
   "source": [
    "### Data Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9da8e1e-a544-4c15-b4bc-e6067c110f6a",
   "metadata": {},
   "source": [
    "#### Select Features and Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f38e23b-5119-4085-b179-cb811cf69c36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7950c401-8f51-404c-98d2-da7099403c34",
   "metadata": {},
   "source": [
    "#### Split data into Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01707c4e-e1b3-4467-9911-0da9a92c91cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b20b516-a3a6-49d1-b02d-fba718da2b10",
   "metadata": {},
   "source": [
    "#### Build Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8938f37-495f-4e44-b9e6-ee5e887a2dd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f31d6a2-5ea7-4f9a-b0f3-0efdf0eb644c",
   "metadata": {},
   "source": [
    "#### Predict Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74b68f3-6680-492c-aaa0-9d2d4551b650",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22ec894b-317b-498c-94a9-a2e318468b00",
   "metadata": {},
   "source": [
    "#### Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5b38d1-d1dc-4762-9bb0-59876cba6c20",
   "metadata": {},
   "source": [
    "#### Accuracy: \n",
    "The proportion of correctly predicted instances (both positive and negative) out of the total number of instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a5a873-44fe-4c9e-afc1-783443084d91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c36a3e3b-c377-453c-a32e-0901c0c7a130",
   "metadata": {},
   "source": [
    "#### Confusion Matrix: \n",
    "A table showing the counts of true positives (TP), true negatives (TN), false positives (FP), and false negatives (FN). From the confusion matrix, other evaluation metrics can be calculated.\n",
    "\n",
    "- Interpreting confusion matrix\n",
    "  \n",
    "    - True Positive (TP): The number of instances that were correctly predicted as positive (or belonging to the positive class) by the model.\n",
    "\n",
    "    - True Negative (TN): The number of instances that were correctly predicted as negative (or belonging to the negative class) by the model.\n",
    "\n",
    "    - False Positive (FP): The number of instances that were incorrectly predicted as positive (predicted positive, but actually negative) by the model. Also known as Type I error.\n",
    "\n",
    "    - False Negative (FN): The number of instances that were incorrectly predicted as negative (predicted negative, but actually positive) by the model. Also known as Type II error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375d4ba4-2e84-4951-8f36-7aa93ae47aee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f702d6b2-faaf-41d2-8657-4ea28dedecd1",
   "metadata": {},
   "source": [
    "<hr><hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bb706e-8c7e-40da-a904-1beac985d92f",
   "metadata": {},
   "source": [
    "#### Common Date and Time Formats\n",
    "\n",
    "**Year-Month-Day**\n",
    "\n",
    "- '%Y-%m-%d' — e.g., 2024-09-06\n",
    "- %Y: Year with century (e.g., 2024)\n",
    "- %m: Month as a zero-padded decimal number (e.g., 09)\n",
    "- %d: Day of the month as a zero-padded decimal number (e.g., 06)\n",
    "\n",
    "**Month-Day-Year**\n",
    "\n",
    "- '%m-%d-%Y' — e.g., 09-06-2024\n",
    "- %m: Month as a zero-padded decimal number (e.g., 09)\n",
    "- %d: Day of the month as a zero-padded decimal number (e.g., 06)\n",
    "- %Y: Year with century (e.g., 2024)\n",
    "\n",
    "**Day-Month-Year**\n",
    "\n",
    "- '%d-%m-%Y' — e.g., 06-09-2024\n",
    "- %d: Day of the month as a zero-padded decimal number (e.g., 06)\n",
    "- %m: Month as a zero-padded decimal number (e.g., 09)\n",
    "- %Y: Year with century (e.g., 2024)\n",
    "- Year-Month-Day Hour:Minute\n",
    "\n",
    "**'%Y-%m-%d %H:%M:%S' — e.g., 2024-09-06 14:30:00**\n",
    "- %Y: Year with century (e.g., 2024)\n",
    "- %m: Month as a zero-padded decimal number (e.g., 09)\n",
    "- %d: Day of the month as a zero-padded decimal number (e.g., 06)\n",
    "- %H: Hour (24-hour clock) as a zero-padded decimal number (e.g., 14)\n",
    "- %M: Minute as a zero-padded decimal number (e.g., 30)\n",
    "- %S: Second as a zero-padded decimal number (e.g., 00)\n",
    "\n",
    "\n",
    "**Month Day, Year Hour:Minute**\n",
    "\n",
    "- '%B %d, %Y %H:%M:%S' — e.g., September 06, 2024 14:30:00\n",
    "- %B: Full month name (e.g., September)\n",
    "- %d: Day of the month as a zero-padded decimal number (e.g., 06)\n",
    "- %Y: Year with century (e.g., 2024)\n",
    "- %H: Hour (24-hour clock) as a zero-padded decimal number (e.g., 14)\n",
    "- %M: Minute as a zero-padded decimal number (e.g., 30)\n",
    "- %S: Second as a zero-padded decimal number (e.g., 00)\n",
    "\n",
    "**Day Month Year**\n",
    "\n",
    "- '%d %b %Y' — e.g., 06 Sep 2024\n",
    "- %d: Day of the month as a zero-padded decimal number (e.g., 06)\n",
    "- %b: Abbreviated month name (e.g., Sep)\n",
    "- %Y: Year with century (e.g., 2024)\n",
    "\n",
    "#### ISO 8601 Format\n",
    "\n",
    "- '%Y-%m-%dT%H:%M:%S' — e.g., 2024-09-06T14:30:00\n",
    "- %Y: Year with century (e.g., 2024)\n",
    "- %m: Month as a zero-padded decimal number (e.g., 09)\n",
    "- %d: Day of the month as a zero-padded decimal number (e.g., 06)\n",
    "- %H: Hour (24-hour clock) as a zero-padded decimal number (e.g., 14)\n",
    "- %M: Minute as a zero-padded decimal number (e.g., 30)\n",
    "- %S: Second as a zero-padded decimal number (e.g., 00)\n",
    "\n",
    "**Year-Month-Day Hour**\n",
    "\n",
    "- '%Y-%m-%d %H:%M' — e.g., 2024-09-06 14:30\n",
    "- %Y: Year with century (e.g., 2024)\n",
    "- %m: Month as a zero-padded decimal number (e.g., 09)\n",
    "- %d: Day of the month as a zero-padded decimal number (e.g., 06)\n",
    "- %H: Hour (24-hour clock) as a zero-padded decimal number (e.g., 14)\n",
    "- %M: Minute as a zero-padded decimal number (e.g., 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7085a43b-6d1e-4a54-bc99-488755ceefa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"SeaPlaneTravel.csv\")\n",
    "df['Month'] = pd.to_datetime(df['Month'], format='%Y-%m')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bce88f-2f4e-48db-979e-1076dcea5934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data to inspect trends\n",
    "sns.lineplot(df, x=\"Month\", y = \"#Passengers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906746ed-7b2f-451f-a688-a1e3aa95eef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "# Perform seasonal decomposition\n",
    "decomposition = seasonal_decompose(df['#Passengers'], model='additive', period=30)\n",
    "\n",
    "# Plot the decomposition\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "plt.subplot(4, 1, 1)\n",
    "plt.plot(df[\"Month\"], df['#Passengers'], label='Original')\n",
    "plt.legend(loc='best')\n",
    "plt.title('Original Time Series')\n",
    "plt.gca().xaxis.set_major_formatter(plt.matplotlib.dates.DateFormatter('%Y-%m'))\n",
    "plt.gca().xaxis.set_major_locator(plt.matplotlib.dates.MonthLocator(interval = 5))\n",
    "plt.xticks(rotation=45) \n",
    "\n",
    "plt.subplot(4, 1, 2)\n",
    "plt.plot(df[\"Month\"], decomposition.trend, label='Trend')\n",
    "plt.legend(loc='best')\n",
    "plt.title('Trend Component')\n",
    "plt.gca().xaxis.set_major_formatter(plt.matplotlib.dates.DateFormatter('%Y-%m'))\n",
    "plt.gca().xaxis.set_major_locator(plt.matplotlib.dates.MonthLocator(interval = 5))\n",
    "plt.xticks(rotation=45) \n",
    "\n",
    "plt.subplot(4, 1, 3)\n",
    "plt.plot(df[\"Month\"],decomposition.seasonal, label='Seasonal')\n",
    "plt.legend(loc='best')\n",
    "plt.title('Seasonal Component')\n",
    "\n",
    "plt.subplot(4, 1, 4)\n",
    "plt.plot(df[\"Month\"], decomposition.resid, label='Residual')\n",
    "plt.legend(loc='best')\n",
    "plt.title('Residual Component')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691cb9e3-e81b-4068-b82f-814ec0a07c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Step 2: Preprocess Data\n",
    "# Check for stationarity (use differencing if needed)\n",
    "df_diff = df['#Passengers'].diff().dropna().to_frame()\n",
    "\n",
    "# Step 3: Split Data into Training and Testing\n",
    "train_size = int(len(df) * 0.8)\n",
    "train, test = df['#Passengers'][:train_size], df['#Passengers'][train_size:]\n",
    "\n",
    "\n",
    "# Step 4: Build the ARIMA Model\n",
    "model = ARIMA(train, order=(5, 1, 2))  # The (p, d, q) parameters can be tuned\n",
    "model_fit = model.fit()\n",
    "\n",
    "# Step 5: Make Predictions\n",
    "predictions = model_fit.forecast(steps=len(test))\n",
    "\n",
    "# Step 6: Evaluate the Model\n",
    "rmse = np.sqrt(mean_squared_error(test, predictions))\n",
    "print(f\"Test RMSE: {rmse}\")\n",
    "\n",
    "# Plot Actual vs Predicted\n",
    "plt.plot(test.index, test, label='Actual')\n",
    "plt.plot(test.index, predictions, label='Forecast', color='red')\n",
    "plt.title('ARIMA Model - Forecast vs Actual')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b961faf-fae5-4371-83d6-0e9e0a6e803e",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_values = np.random.normal(loc=3, scale=1, size=99)\n",
    "normal_values = np.clip(normal_values, 1, 5)\n",
    "df = pd.DataFrame({\"cust\" : np.arange(1, 100), \"hrs\" : normal_values })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab8460a-5e0c-4b4b-9ee2-216a0d894f75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd936920-905e-4cdd-ab65-12e6d344abcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20de920-966f-4f8c-b951-30d77812939f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8805976f-eda9-4471-9527-1273328e9a8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e0e28d-1046-4038-9520-b013e1853148",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e01b95-06ad-41e7-8600-9f600566deb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761afeb3-1c37-454b-b851-a7e2725f21f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd889bf-c356-48ad-b3f9-705de43b82f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1d4304-685d-4fff-880c-bf77d3313f01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b16bdbc-c94a-44b5-9f7f-a4f355fe3d1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b59be4-d1e3-410a-9c80-9f39f01dfd42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395a73f5-fa12-42ab-895b-97bcf8c31a3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce525591-5579-4226-b835-c3496d97d070",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a54e82-3814-4d8f-9daf-74f92b662d2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f73826-d4e6-4a35-98af-bd805513ccc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d158c8d-54b5-42ec-8848-40bb127a26ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025be169-adea-4326-b453-e560c20e6a9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4ee625-cdef-44a8-94c7-933b32002860",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862cf4b9-cdae-414c-bfa2-2005a21983c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9d8e10-8efd-4d3f-9b59-7eeaa5e502eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3226a668-83c0-4366-b1fb-6165d415832c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6bd7c1-dad4-41b9-8984-977dd4967129",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90207e43-2a71-4ad2-a5e8-7ca75c0b13c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23556ada-3dd3-4db3-8388-d04581a2e2a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb080a7-bdfa-4e46-8226-ce6cfc26116a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ac7fe0-cdf4-4443-b756-0a3c9c3f83bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852876df-9771-472f-aefb-233328b50023",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c807c20-0c98-483a-b223-20bee2685bc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09bea05d-6cb3-4d34-ba77-86dc7ffcc15a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c54ac96-32b7-40e3-8659-359b96db69e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c9ed69-c911-42ca-86d7-1dd4dcbdb1b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d864c79f-a1bb-403f-9ea4-b4f3b201ef84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40a20cb-31f2-4c0b-8ab8-85e42ccf258c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7ed966-0aba-4c1a-9afc-cc0e85e37630",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40491e7b-f385-4c38-a312-80dcef1336fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
